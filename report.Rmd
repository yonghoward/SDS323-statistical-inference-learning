---
title: 'The 2019-20 NBA Season: What Could Have Been'
author:
- Ryan Kohanski
- Rithvik Saravanan
- Howard Yong
date: "May 11, 2020"
output:
  pdf_document:
    extra_dependencies: float
    fig_caption: yes
indent: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.pos = 'H')
```

```{r libraries, include=FALSE}
library(elo)
library(tidyverse)
library(mosaic)
library(ggplot2)
library(reshape2)
library(foreach)
library(data.table)
library(magrittr)
library(dplyr)
library(stringr)
library(elo)
library(rvest)
library(lubridate)
library(cluster)
library(FNN)
library(glmnet)
library(knitr)
```

```{r data, include=FALSE}
season2016_2017 = read.csv('./data/nba-scrape-data-2016-2017.csv', header=TRUE)
season2017_2018 = read.csv('./data/nba-scrape-data-2017-2018.csv', header=TRUE)
season2018_2019 = read.csv('./data/nba-scrape-data-2018-2019.csv', header=TRUE)
season2019_2020 = read.csv('./data/nba-scrape-data-2019-2020.csv', header=TRUE)
remaining_games_19_20 <- read.csv('./data/nba-remaining-games-2019-2020.csv', header=TRUE)
player_stats = read.csv('./data/nba_19-20_player_stats.csv', header=TRUE)
nba_elo_rating_19_20 = read.csv('./data/nba-elo-current-2019-2020.csv', header=TRUE)
```


# Abstract

The COVID-19 pandemic has affected our society in various ways and has changed numerous events on schedule for 2020. One such event that we were looking forward to was the end of the 2019-20 NBA season as well as the 2020 NBA Playoffs. Since a large portion of the 2019-20 NBA regular season games have already been played, we utilized the data collected from these games to run regression prediction models and calculate Elo ratings for each team in order to predict the standings for 2019-20 as well as the matchups and results of the Playoffs and the NBA season awards. Using the Elo rating predictions by matchup, we predicted that the Milwaukee Bucks ended with the highest seeding (standing) at the end of the season with the Los Angeles Lakers coming in second. Running our analysis by predicting the 7-game playoff series matchups, we predicted that the Western Conference Finals matchup will be between the #1 seed Los Angeles Lakers and the #2 seed Los Angeles Clippers and the Eastern Conference Finals matchup will be between the #1 seed Milwaukee Bucks and the #2 seed Toronto Raptors. We found that running these simulations predicts the NBA Finals matchup between the Los Angeles Lakers and the Milwaukee Bucks with the Los Angeles Lakers ultimately claiming the Larry O'Brien NBA Championship Trophy. Additionally, we used several types of regression models to best predict end-of-season statistics for every player. We ultimately used a logistic regression model to predict the end-of-season statistics and leaders for each of the major categories and found that our predictions indicate that Giannis Antetokounmpo will claim both the NBA Most Valuable Player (MVP) award as well as the Defensive Player of the Year (DPOY) award. According to our prediction model, this will mark only the third time in NBA history that a player will win MVP and DPOY in the same season with the previous two players being basketball legends Michael Jordan and Hakeem Olajuwon.



# Introduction

Due to the widespread impact of the COVID-19 pandemic throughout the world, almost every company, organization, and public event has canceled or suspended any activities that involve interpersonal contact for the forseeable future. Many of these activities are moving to a virtual format if possible, but several others have been forced to shut down.

As avid sports fans, the absence of the major sporting events during this time has hit us and many others around the world especially hard [1]. Some of the events that we particularly were looking forward to include the NBA, NCAA March Madness tournament, MLB, and the 2020 Summer Olympics.

In our curiosity, we decided to utilize this opportunity to exercise our data science and modeling skills in order to predict what could have been. Specifically, we focused on the NBA and the NBA Playoffs. Since the 2019-20 NBA season was suspended approximately one month prior to the end of the regular season (and the beginning of the Playoffs), we used the 2019-20 season data accumulated from the games played before the suspension to predict how the season and the Playoffs would have ended had everything gone according to schedule.

In this analysis, we will examine data from the 2019-20 NBA season as well as some data from previous NBA seasons in order to draw some meaningful conclusions about the remainder of the 2019-20 NBA season including the final season standings, playoff matchups, championship winner, and season award winners.



# Methods


## Predicting the 2019-20 NBA Season Standings

Since we missed one of the most exciting times of the year (the NBA Playoffs & Finals), we made some predictions on how the rest of the season might have played out using a popular methodology referred to as the Elo ratings system [2]. This tool, created by Hungarian-American physics professor Arpad Elo, was orginally designed to rate chess players, but is now used for all sorts of competitions ranging anywhere from sports to video games. This is a methodology that FiveThirtyEight and many other popular sports analysts take advantage of due to its simplicity and effectiveness [3].

These ratings depend only on the final score of each game as well as where it was played (home-court advantage). In other words, this system is built on a Win/Loss basis. We will be analyzing the 2018-19 NBA Season in its entirety to validate its performance, then we will apply it to the 2019-20 regular season in order to predict the matchups for the Playoffs and the Finals and ultimately the NBA Champions. For this project, we retrieved several types of data sources including game-by-game scores and schedules for several seasons from Basketball-Reference.com [4].


### How does Elo work?

The long-run average for an Elo score in the NBA sits around 1500. An Elo of 1500 means that the teams performance would be normally distrubuted around an average of 1500 with the chance of performing better or worse. For more detail, Figure \ref{fig:elo_chart} (Appendix) shows what an Elo rating tells us about a team and how it can convey the teams overall season record. A higher Elo rating indicates that the team has a high win-loss ratio and is more likely to play deeper into the season.

The formula for Elo below shows how the probability of one team beating another is calculated using the ratings. When Player $A$ competes in a match against Player $B$, Player $A$ has an expected outcome (probability or score) for Team $A$ ($E[A]$) where $R_A$ is the rating for Team $A$ and $R_B$ is the rating for Team $B$. The expected outcome for Team $A$ ($E[A]$) can be calculated by the formula below:

$$
E[A] = \frac{1}{1 + 10^{\frac{(R_B-R_A)}{400}}}
$$

The same calculation ($E[B]$) has to be done for Player $B$, but with $R_A$ (current rating $A$) and $R_B$ (current rating $B$) swapped so that $E[A] + E[B] = 1$. Once the match is played and $S_A$ (actual outcome or score for Team $A$) and $S_B$ (actual outcome or score for Team $B$) are determined, $R^{\prime}_A$ (the new rating for $A$) and $R^{\prime}_B$ (the new rating for $A$) are calculated with the formula below:

$$
R^{\prime}_A=R_A+K(S_A-E[A])
$$

The $S$ value in our case would either be 1 for a win, or 0 for a loss. This is because there are no ties in the NBA.

In this equation, $K$ is an optimization constant that usually takes different values according the sport and the amount of games available. In other words, this value is the maximum amount by which a score can change in one match. If $K$ is set too high, the ratings will jump around too much; if $K$ is set too low, Elo will take too long to recognize important changes in team quality. Determining the right value of K is an entirely different and more complicated topic, so for this experiment we will be using $K=20$, the optimal $K$ for the NBA determined by FiveThirtyEight [3]. This is higher than most other sports and can likely be attributed to the fact that the NBA plays more games (81 games per team) and is subject to relatively little randomness.

Home-court advantage is set as equivalent to 100 Elo rating points. One hundred Elo points is equivalent to about 3.5 NBA points, so it can also be interpreted as the home team being favored by 3 to 4 points if the teams were otherwise evenly matched (obviously this value fluctuates from season to season). Since every team plays about half of their games at home and the other half away, a change in the home-court advantage value does not produce a significant difference in the ratings, but is still an important factor to consider.

Elo strikes a nice balance between ratings systems that account for margin of victory and those that do not. While teams always gain Elo points after wins and lose Elo points after losses, they also gain or lose more with larger margins of victory.

This works by assigning a multiplier to each game based on the final score and dividing it by a team’s projected margin of victory conditional upon having won the game. For instance, the Golden State Warriors' 4-point margin over the Houston Rockets in Game 1 of the 2018-19 Western Conference finals was lower than Elo would expect for a Warriors win. So the Warriors gain Elo points, but not as many as if they’d won by a larger margin. The formula accounts for diminishing returns; going from a 5-point win to a 10-point win matters more than going from a 25-point win to a 30-point win. For the exact formula, see the footnotes.

Instead of resetting each team’s rating when a new season begins, Elo carries over a portion of a team’s rating from one season to the next. This is to account for any momentum that a team may build from season-to-season (i.e. sports dynasties). In NBA ratings, three-quarters of the previous score are kept. The high fraction reflects the fact that NBA teams are more consistent from year to year. For example, the Miami Heat ended the 2012-13 NBA season with an Elo rating of 1754. The team’s Elo rating for the start of the 2013-14 season is calculated as follows:

$$
(0.75 * 1754) + (0.25 * 1500) = 1692
$$

Since this is a consistent method, we will also initialize the Elo scores for the 2019-20 NBA Season using the Elo scores from the 2018-19 season.

After incorporating a constant for home court advantage, our formula is as follows with $A=100$ points (the value we previously determined represents a home-court advantage):

$$
P(\mbox{Home team wins}) = \frac{1}{1 + 10^{-\frac{(H-R+A)}{400}}}
$$

```{r elo_logit, echo=FALSE, out.width='100%', fig.width = 8, fig.height = 5, fig.align='center', out.width='.49\\linewidth', fig.cap="\\label{fig:logit}Logistic Function of Win Probability by Elo Rating Difference", comment=NA, warning=FALSE}
include_graphics('./logistic.png')
```

In Figure \ref{fig:logit}, we see an example of a logistic function for win probability by Elo rating difference. The key takeaway from this figure is that the higher the difference between the teams' Elo ratings, the more likely that the team with the higher Elo rating is to win.


### Calculating Elo Ratings

For our project scope, we decided to model our Elo rating system purely off of home-court advantage, wins, losses, and point-margin differentials. Of course, in the NBA, there is a wide array of different factors to consider, including roster changes, injuries, winning streaks, etc. These are all features that limit the capabilities of our model, but serve as potential targets of investigation for the future. As we mentioned before, one principal task of our project was to explore outcomes of the 2019-20 NBA season if the games were to continue. In order to do so, we first needed to develop Elo ratings for each team at their current state of the 2019-20 season. Online resources report that the NBA has historically shown an average Elo rating of 1505, as the league is continually experiencing expansions and contractions that influence the center of the distribution of team ratings [3]. Accordingly, we followed this statistic in our Elo rating calculations. When simulating Elo rating calculations for each team throughout multiple seasons, we preemptively decided to carry over 75% of each team's Elo rating from the previous season, with the other 25% weight carried by the league average of 1505. This proportion was determined through historical league analyses of the NBA.

For the scope of our analysis, we decided to begin our analysis in the 2016-17 NBA season. We chose to start our calculations from this season because the season data was readily available and provided enough years to build a more-updated status of each team's current standing in the league. Once we had collected the data for the NBA seasons, we calculated the Elo ratings by the aforementioned methods. We iterated through the season by matchup, calculating and updating the Elo ratings for the teams playing simultaneously, and applied this to every season until 2019-20.

```{r, include=FALSE, warning=FALSE}
yearList <- c('2020')
monthList <- c('october', 'november', 'december', 'january', 'february',
               'march')

df <- data.frame()
for (year in yearList) {
  if (year == '2020') {
    monthList <- c('october', 'november', 'december', 'january', 'february', 'march')
  }
  for (month in monthList) {
    # get webpage
    url <- paste0("https://www.basketball-reference.com/leagues/NBA_", year, 
                  "_games-", month, ".html")
    webpage <- read_html(url)
    
    # get column names
    col_names <- webpage %>% 
      html_nodes("table#schedule > thead > tr > th") %>% 
      html_attr("data-stat")    
    col_names <- c("game_id", col_names)
    
    # extract dates column
    # note that in april, there is a break in the table which just says 
    # "Playoffs". this messes with the data merging later, so we get rid of it
    dates <- webpage %>% 
      html_nodes("table#schedule > tbody > tr > th") %>% 
      html_text()
    dates <- dates[dates != "Playoffs"]
    
    # extract game id
    # we need to remove the NA that is due to the "Playoffs" row in april
    game_id <- webpage %>% 
      html_nodes("table#schedule > tbody > tr > th") %>%
      html_attr("csk")
    game_id <- game_id[!is.na(game_id)]
    
    # extract all columns (except date)
    data <- webpage %>% 
      html_nodes("table#schedule > tbody > tr > td") %>% 
      html_text() %>%
      matrix(ncol = length(col_names) - 2, byrow = TRUE)
    
    # combine game IDs, dates and columns in dataframe for this month, add col names
    month_df <- as.data.frame(cbind(game_id, dates, data), stringsAsFactors = FALSE)
    names(month_df) <- col_names
    
    # add to overall dataframe
    df <- rbind(df, month_df)
  }
}
# change columns to the correct types
df$visitor_pts <- as.numeric(df$visitor_pts)
df$home_pts    <- as.numeric(df$home_pts)
df$attendance  <- as.numeric(gsub(",", "", df$attendance))
df$date_game   <- mdy(df$date_game)
df$box_score_text <- NULL

# add home team winner column
df$home_team_wins <- with(df, ifelse(home_pts > visitor_pts, 1, 0))

# save to file
df
head(df)
tail(df)
```

```{r, include=FALSE, warning=FALSE}
nbateams <- data.frame(team = unique(c(df$home_team_name, df$visitor_team_name)))
nbateams <- nbateams %>% mutate(elo=1500)
nbateams$X <- NULL
nbateams

season2016_2017 = read.csv('./data/nba-scrape-data-2016-2017.csv')
season2017_2018 = read.csv('./data/nba-scrape-data-2017-2018.csv')
season2018_2019 = read.csv('./data/nba-scrape-data-2018-2019.csv')
season2019_2020 = read.csv('./data/nba-scrape-data-2019-2020.csv')
head(season2016_2017)
tail(season2016_2017)


#==============================================2016-2017==============================================
#Create different data.frames by team<#>
temp <- paste('team', 1:30, sep="")
for (i in 1:30) {
  assign(paste("team",i,sep=""), cbind(rep(0,250)) )
}

for (i in seq(nrow(season2016_2017))) {
  match <- season2016_2017[i, ]
  
  #Pre-match ratings
  teamA_elo <- subset(nbateams, team==match$home_team_name)$elo
  teamB_elo <- subset(nbateams, team==match$visitor_team_name)$elo
  
  #Update our ratings
  new_elo <- elo.calc(wins.A = match$home_team_wins,
                      elo.A = teamA_elo,
                      elo.B = teamB_elo,
                      k = 20)
  
  #Results reported as data.frame
  #Team A's new rating in row1/column1
  #Team B's new rating in row1/column2
  new_elo
  teamA_new_elo <- new_elo[1,1]
  teamB_new_elo <- new_elo[1,2]
  
  #Update the ratings for Teams A and B and leave other teams as they were
  nbateams <- nbateams %>%
    mutate(elo = if_else(team==match$home_team_name, teamA_new_elo,
                         if_else(team==match$visitor_team_name, teamB_new_elo, elo)))
  
  home_idx = match(match$home_team_name, nbateams$team)
  visitor_idx = match(match$visitor_team_name, nbateams$team)
  temp_home = paste('team', home_idx, sep="")
  temp_visitor = paste('team', visitor_idx, sep="")
  update_home = get(temp_home)
  update_visitor = get(temp_visitor)
  
  for (i in 1:length(update_home)) {
    if (update_home[i,]==0) {
      update_home[i,] = teamA_new_elo
      break
    }
  }
  assign(paste('team', home_idx, sep=""), update_home)
  
  for (i in 1:length(update_visitor)) {
    if (update_visitor[i,]==0) {
      update_visitor[i,] = teamB_new_elo
      break
    }
  }
  assign(paste('team', visitor_idx, sep=""), update_visitor)
}
options(digits=8)
nbateams %>%
  arrange(-elo)
avg_season_elo = 1505

elo_2016_2017 <- sapply(temp, get)
head(elo_2016_2017)
tail(elo_2016_2017)

c = 1
for (team in nbateams$team) {
  colnames(elo_2016_2017)[c] = team
  c = c + 1
}
tail(elo_2016_2017)
write.csv(elo_2016_2017, './data/elo_2016_2017.csv')


```

```{r, include=FALSE}
options(digits=8)
nbateams %>%
  arrange(-elo)
```

```{r, warning=FALSE, comment=NA, include=FALSE}
nbateams <- nbateams %>% mutate(elo=0.75*elo+.25*avg_season_elo)
nbateams %>%
  arrange(-elo)

#==============================================2017-2018==============================================
#Create different data.frames by team<#>
temp <- paste('team', 1:30, sep="")
for (i in 1:30) {
  assign(paste("team",i,sep=""), cbind(rep(0,250)) )
}

for (i in seq(nrow(season2017_2018))) {
  match <- season2017_2018[i, ]
  
  #Pre-match ratings
  teamA_elo <- subset(nbateams, team==match$home_team_name)$elo
  teamB_elo <- subset(nbateams, team==match$visitor_team_name)$elo
  
  #Update our ratings
  new_elo <- elo.calc(wins.A = match$home_team_wins,
                      elo.A = teamA_elo,
                      elo.B = teamB_elo,
                      k = 20)
  
  #Results reported as data.frame
  #Team A's new rating in row1/column1
  #Team B's new rating in row1/column2
  new_elo
  teamA_new_elo <- new_elo[1,1]
  teamB_new_elo <- new_elo[1,2]
  
  #Update the ratings for Teams A and B and leave other teams as they were
  nbateams <- nbateams %>%
    mutate(elo = if_else(team==match$home_team_name, teamA_new_elo,
                         if_else(team==match$visitor_team_name, teamB_new_elo, elo)))
  
  home_idx = match(match$home_team_name, nbateams$team)
  visitor_idx = match(match$visitor_team_name, nbateams$team)
  temp_home = paste('team', home_idx, sep="")
  temp_visitor = paste('team', visitor_idx, sep="")
  update_home = get(temp_home)
  update_visitor = get(temp_visitor)
  
  for (i in 1:length(update_home)) {
    if (update_home[i,] == 0) {
      update_home[i,] = teamA_new_elo
      break
    }
  }
  assign(paste('team', home_idx, sep=""), update_home)
  
  for (i in 1:length(update_visitor)) {
    if (update_visitor[i,] == 0) {
      update_visitor[i,] = teamB_new_elo
      break
    }
  }
  assign(paste('team', visitor_idx, sep=""), update_visitor)
}
options(digits=8)
nbateams %>%
  arrange(-elo)
avg_season_elo = 1505

elo_2017_2018 <- sapply(temp, get)
c = 1
for (team in nbateams$team) {
  colnames(elo_2017_2018)[c] = team
  c = c + 1
}
write.csv(elo_2017_2018, './data/elo_2017_2018.csv')

nbateams <- nbateams %>% mutate(elo=0.75*elo+.25*avg_season_elo)
nbateams %>%
  arrange(-elo)

#==============================================2018-2019==============================================
#Create different data.frames by team<#>
temp <- paste('team', 1:30, sep="")
for (i in 1:30) {
  assign(paste("team",i,sep=""), cbind(rep(0,250)) )
}

for (i in seq(nrow(season2018_2019))) {
  match <- season2018_2019[i, ]
  
  #Pre-match ratings
  teamA_elo <- subset(nbateams, team==match$home_team_name)$elo
  teamB_elo <- subset(nbateams, team==match$visitor_team_name)$elo
  
  #Update our ratings
  new_elo <- elo.calc(wins.A = match$home_team_wins,
                      elo.A = teamA_elo,
                      elo.B = teamB_elo,
                      k = 20)
  
  #Results reported as data.frame
  #Team A's new rating in row1/column1
  #Team B's new rating in row1/column2
  new_elo
  teamA_new_elo <- new_elo[1,1]
  teamB_new_elo <- new_elo[1,2]
  
  #Update the ratings for Teams A and B and leave other teams as they were
  nbateams <- nbateams %>%
    mutate(elo = if_else(team==match$home_team_name, teamA_new_elo,
                         if_else(team==match$visitor_team_name, teamB_new_elo, elo)))
  
  home_idx = match(match$home_team_name, nbateams$team)
  visitor_idx = match(match$visitor_team_name, nbateams$team)
  temp_home = paste('team', home_idx, sep="")
  temp_visitor = paste('team', visitor_idx, sep="")
  update_home = get(temp_home)
  update_visitor = get(temp_visitor)
  
  for (i in 1:length(update_home)) {
    if (update_home[i,] == 0) {
      update_home[i,] = teamA_new_elo
      break
    }
  }
  assign(paste('team', home_idx, sep=""), update_home)
  
  for (i in 1:length(update_visitor)) {
    if (update_visitor[i,] == 0) {
      update_visitor[i,] = teamB_new_elo
      break
    }
  }
  assign(paste('team', visitor_idx, sep=""), update_visitor)
}
options(digits=8)
nbateams %>%
  arrange(-elo)
avg_season_elo = 1505

elo_2018_2019 <- sapply(temp, get)
c = 1
for (team in nbateams$team) {
  colnames(elo_2018_2019)[c] = team
  c = c + 1
}
write.csv(elo_2018_2019, './data/elo_2018_2019.csv')

nbateams <- nbateams %>% mutate(elo=0.75*elo+.25*avg_season_elo)
nbateams %>%
  arrange(-elo)

#==============================================2019-2020==============================================
#Create different data.frames by team<#>
temp <- paste('team', 1:30, sep="")
for (i in 1:30) {
  assign(paste("team",i,sep=""), cbind(rep(0,250)) )
}

for (i in seq(nrow(season2019_2020))) {
  match <- season2019_2020[i, ]
  
  #Pre-match ratings
  teamA_elo <- subset(nbateams, team==match$home_team_name)$elo
  teamB_elo <- subset(nbateams, team==match$visitor_team_name)$elo
  
  #Update our ratings
  new_elo <- elo.calc(wins.A = match$home_team_wins,
                      elo.A = teamA_elo,
                      elo.B = teamB_elo,
                      k = 20)
  
  #Results reported as data.frame
  #Team A's new rating in row1/column1
  #Team B's new rating in row1/column2
  new_elo
  teamA_new_elo <- new_elo[1,1]
  teamB_new_elo <- new_elo[1,2]
  
  #Update the ratings for Teams A and B and leave other teams as they were
  nbateams <- nbateams %>%
    mutate(elo = if_else(team==match$home_team_name, teamA_new_elo,
                         if_else(team==match$visitor_team_name, teamB_new_elo, elo)))
  
  home_idx = match(match$home_team_name, nbateams$team)
  visitor_idx = match(match$visitor_team_name, nbateams$team)
  temp_home = paste('team', home_idx, sep="")
  temp_visitor = paste('team', visitor_idx, sep="")
  update_home = get(temp_home)
  update_visitor = get(temp_visitor)
  
  for (i in 1:length(update_home)) {
    if (update_home[i,] == 0) {
      update_home[i,] = teamA_new_elo
      break
    }
  }
  assign(paste('team', home_idx, sep=""), update_home)
  
  for (i in 1:length(update_visitor)) {
    if (update_visitor[i,] == 0) {
      update_visitor[i,] = teamB_new_elo
      break
    }
  }
  assign(paste('team', visitor_idx, sep=""), update_visitor)
}
options(digits=8)
nbateams %>%
  arrange(-elo)
avg_season_elo = 1505

elo_2019_2020 <- sapply(temp, get)
c = 1
for (team in nbateams$team) {
  colnames(elo_2019_2020)[c] = team
  c = c + 1
}
write.csv(elo_2019_2020, './data/elo_2019_2020.csv')

names(nbateams)[1] <- paste("Team Name")
names(nbateams)[2] <- paste("Elo Rating")
write.csv(nbateams, './data/nba-elo-current-2019-2020.csv')
nbateams = read.csv('./data/nba-elo-current-2019-2020.csv')
seasonelo = read.csv('./data/elo_2019_2020.csv')

seasonelo$X = NULL
library(reshape2)
elo2019_2020 <- melt(seasonelo)
elo_df <- melt(elo_2019_2020)
colnames(elo_df) <- c("Games.Played", "Team", "Elo.Rating")
elo_df <- elo_df[(elo_df$Elo.Rating > 0),]
western_conf = c('Lost Angeles Lakers', "Golden State Warriors", "Houston Rockets", "San Antonio Spurs",
                 'Oklahoma City Thunder', 'Portland Trail Blazers', 'Dallas Mavericks', 'Phoenix Suns',
                 'Los Angeles Clippers', 'Utah Jazz', 'Denver Nuggets', 'Memphis Grizzlies',
                 'Minnesota Timberwolves', 'New Orleans Pelicans', 'Sacramento Kings')
eastern_conf = c('Chicago Bulls', 'Cleveland Cavaliers', 'Boston Celtics', 'New York Knicks', 'Toronto Raptors',
                 'Miami Heat', 'Indiana Pacers', 'Detroit Pistons', 'Philadelphia 76ers', 'Milwaukee Bucks',
                 'Brooklyn Nets', 'Orlando Magic', 'Washington Wizards', 'Atlanta Hawks', 'Charlotte Hornets')
elo_df$Conference = if_else(elo_df$Team %in% western_conf, "West", "East")

ggplot(elo_df, aes(x=Games.Played, y=Elo.Rating, color=Team)) + geom_line() + facet_grid(elo_df$Conference~.)

nbateams$X = NULL
nbateams$Conference <- if_else(nbateams$Team.Name %in% western_conf, "West", "East")
names(nbateams)[1] <- paste('Team')
names(nbateams)[2] <- paste('Elo Rating')
nbateams  
```

After calculating the Elo rating as mentioned earlier, we ended up with the Elo ratings of the NBA teams at the beginning of the 2019-20 season. We tracked their progress throughout this year's season and plotted them in the figure below. The plot is facetted by Conferences (East and West), which determines how many times a team plays other teams, as well as who they may contend against in their playoff runs.

```{r, include=FALSE}
ggplot(elo_df, aes(x=Games.Played, y=Elo.Rating, color=Team)) + geom_line() + facet_grid(elo_df$Conference~.)
nbateams$X = NULL
nbateams
```

### Simulations and Predictions

After calculating the Elo ratings for each NBA team up until the last game they played (before the season was suspended), we used these ratings to then perform simulations matching up teams based on the rest of the season schedule as well as the post-season tournaments based on the top seeded teams from the regular season.

```{r simulations, include=FALSE, warning=FALSE}
# Running simulations on the remaining regular season schedule, then for playoffs, then for finals

# Remainder of regular season
reg_season <- remaining_games_19_20
str(reg_season)
head(reg_season)

reg_season$home_team <- as.character(reg_season$home_team)
reg_season$visitor_team <- as.character(reg_season$visitor_team)

elos <- nba_elo_rating_19_20
head(elos, 30)

elos$Team.Name <- as.character(elos$Team.Name)
str(elos)

# DF to store elos after each game for plotting
elo_history = data.frame(Team.Name = as.character(elos$Team.Name))
elo_history$Elo.Rating = elos$Elo.Rating

# List of winners
winners <- c()

matchups <- reg_season[2:3]
head(matchups)
str(matchups)


#row = 1 # For test purposes
for (row in 1:nrow(matchups)) {
  
  # Home Team and Away Team
  home <- matchups[row, "home_team"]
  away  <- matchups[row, "visitor_team"]
  
  # Pre-match ratings
  x = subset(elos, Team.Name == home)
  elo.A <- (as.integer(c(x[3])) + as.integer(10)) # plus 10/100 represents HCA
  
  y = subset(elos, Team.Name == away)
  elo.B <- as.integer(c(y[3]))
  
  # Probability of winning
  prob.A <- elo.prob(elo.A, elo.B)
  prob.B <- elo.prob(elo.B, elo.A)
  
  # Sample from distribution of size 1 because if repeated the team with higher score is obviously expected to win. this makes it more "random"
  winner <- sample(c(home, away), size=1, prob=c(home=prob.A, away=prob.B))
  
  # Add winner to list of winners for each matchup
  winners <- c(winners, winner)
  
  if (winner == home) {
    result = c(1)
  } else if (winner == away) {
    result = c(0)
  }
  
  # Let's update our ratings
  new_elo <- elo.calc(wins.A = result,
                      elo.A = elo.A, 
                      elo.B = elo.B, 
                      k = 20)
  
  # The results come back as a data.frame
  # with team A's new rating in row 1 / column 1
  # and team B's new rating in row 1 / column 2
  teamA_new_elo <- new_elo[1, 1]
  teamB_new_elo <- new_elo[1, 2]
  
  # We then update the ratings for teams A and B
  # and leave the other teams as they were
  
  elos <- elos %>%
    mutate(Elo.Rating = if_else(Team.Name == home, teamA_new_elo,
                         if_else(Team.Name == away, teamB_new_elo, Elo.Rating)))
  
  # Add updated elos to elo history (FIX THIS)
  elo_history[, paste(as.character("game"), as.character(row), sep="")] <- elos$Elo.Rating
  
}

# After a few minutes, you should get a nice teams data.frame, with the most up-to-date international Elo ratings for June 2018
elos %>%
  arrange(-Elo.Rating) %>%
  head(30)

# Add winners list to the schedule
reg_season$winners = winners
head(reg_season)

# Show Elo History
head(elo_history)

# Playoffs
# The top eight teams in each conference (East and West), ranked in order by win-loss records, qualify for the playoffs.
# Eastern Conference
'
EC <- c("Milwaukee Bucks", "Toronto Raptors", "Boston Celtics", "Miami Heat", "Indiana Pacers", "Philadelphia 76ers", "Brooklyn Nets", "Orlando Magic", 
        "Washington Wizards", "Charlotte Hornets", "Chicago Bulls", "New York Knicks", "Detroit Pistons", "Atlanta HAwks", "Cleveland Cavaliers")
# Western Conference
WC <- c("Los Angeles Lakers", "Los Angeles Clippers", "Denver Nuggets", "Utah Jazz", "Oklahoma City Thunder", "Houston Rockets", "Dallas Mavericks", "Memphis Grizzlies", 
        "Portland Trail Blazers", "New Orleans Pelicans", "Sacramento Kings", "San Antonio Spurs", "Phoenix Suns", "Minnesota Timberwolves", "Golden State Warriors")

eastern_conference = data.frame(team = EC, elo=0, stringsAsFactors = FALSE)
western_conference = data.frame(team = WC, elo=0, stringsAsFactors = FALSE)


for (row in 1:nrow(eastern_conference)) {
  team <- eastern_conference[row, "team"]
  elo  <- eastern_conference[row, "elo"]
  
  team_elo = subset(elos, team == team)
  elo = team_elo
}

for (row in 1:nrow(western_conference)) {
  team <- western_conference[row, "team"]
  elo  <- western_conference[row, "elo"]
  
  team_elo = subset(elos, team == team)
  elo = team_elo
}

# Top 8 in EC
eastern_conference %>%
  arrange(-elo) %>%
  head(8)

# Top 8 in WC
western_conference %>%
  arrange(-elo) %>%
  head(8)
'

# Different Way (TOP 8 TEAMS FROM EACH CONFERENCE)
WC_teams <- elos %>%
  filter(Team.Name %in% c("Los Angeles Lakers", "Los Angeles Clippers", "Denver Nuggets", "Utah Jazz", "Oklahoma City Thunder", "Houston Rockets", "Dallas Mavericks", "Memphis Grizzlies", 
                     "Portland Trail Blazers", "New Orleans Pelicans", "Sacramento Kings", "San Antonio Spurs", "Phoenix Suns", "Minnesota Timberwolves", "Golden State Warriors")) %>%
  arrange(-Elo.Rating) %>%
  head(8)


EC_teams <- elos %>%
  filter(Team.Name %in% c("Milwaukee Bucks", "Toronto Raptors", "Boston Celtics", "Miami Heat", "Indiana Pacers", "Philadelphia 76ers", "Brooklyn Nets", "Orlando Magic", 
                     "Washington Wizards", "Charlotte Hornets", "Chicago Bulls", "New York Knicks", "Detroit Pistons", "Atlanta HAwks", "Cleveland Cavaliers")) %>%
  arrange(-Elo.Rating) %>%
  head(8)

# Each team earns a spot on the playoff bracket, known as a “seed,” which will determine what team they will face off against.
# Seeding is based off of win/loss with ties becomign a bit more complicated through further evaluation
# For this project we will seeed based off of elo scores (very low probability of ties in scores). This also makes sense because elos are based on W/L.
# The conference DFs are already ordered by elo, so we can just put 1-8 as seed
WC_teams$seed <- c(1:8)

EC_teams$seed <- c(1:8)

# Technically there is a system in place designed for HCA in playoffs given to the team with the better record/higher seed
# Each NBA playoff series is composed of 4 to 7 games that are played in a 2-2-1-1-1 format. 
# This means that the team with the home-court advantage hosts games 1, 2, 5, and 7 while its opponent hosts games 3, 4, and 6, with games 5-7 only being played if necessary.
# However, because this complicates our implementation, we will ignore HCA for the playoffs and finals (although it does sometimes have an impact on the result)

# 1st Round - Playoffs (16 teams): Best-of-7 Series
# 1 vs 8, 2 vs 7, 3 vs 6, 4 vs 5
# Make dataframe for matchups
playoffs = data.frame(matrix(ncol = 2, nrow = 8))
colnames(playoffs) <- c("team1", "team2")

# Playoff Schedule
playoffs$team1 <- c(WC_teams[1,2], WC_teams[2,2], WC_teams[3,2], WC_teams[4,2], EC_teams[1,2], EC_teams[2,2], EC_teams[3,2], EC_teams[4,2])
playoffs$team2 <- c(WC_teams[8,2], WC_teams[7,2], WC_teams[6,2], WC_teams[5,2], EC_teams[8,2], EC_teams[7,2], EC_teams[6,2], EC_teams[5,2])

first_round <- c()
#row = 1 # For test purposes
#i = 1 # For test purposes
for (row in 1:nrow(playoffs)) {
  
  # Home Team and Away Team
  team1 <- playoffs[row, "team1"]
  team2  <- playoffs[row, "team2"]
  
  # For loop here? for i in 1:7
  series <- c()
  for (i in 1:7) {
    # Pre-match ratings
    x = subset(elos, Team.Name == team1)
    elo.A <- (as.integer(c(x[3])))
    
    y = subset(elos, Team.Name == team2)
    elo.B <- as.integer(c(y[3]))
    
    # Probability of winning
    prob.A <- elo.prob(elo.A, elo.B)
    prob.B <- elo.prob(elo.B, elo.A)
    
    # Best of 7 series sampling
    winner <- sample(c(team1, team2), size=1, prob=c(prob.A, prob.B), replace=TRUE) # size = 7?
    series <- c(series, winner)
    
    # Add winner to list of winners for each matchup
    #first_round <- c(first_round, winner)
    
    if (winner == team1) {
      result = c(1)
    } else if (winner == team2) {
      result = c(0)
    }
    
    # Let's update our ratings
    new_elo <- elo.calc(wins.A = result,
                        elo.A = elo.A, 
                        elo.B = elo.B, 
                        k = 20)
    
    # The results come back as a data.frame
    # with team A's new rating in row 1 / column 1
    # and team B's new rating in row 1 / column 2
    teamA_new_elo <- new_elo[1, 1]
    teamB_new_elo <- new_elo[1, 2]
    
    # We then update the ratings for teams A and B
    # and leave the other teams as they were
    elos <- elos %>%
      mutate(Elo.Rating = if_else(Team.Name == team1, teamA_new_elo,
                           if_else(Team.Name == team2, teamB_new_elo, Elo.Rating)))
    
    # Add updated elos to elo history
    elo_history[, paste(as.character("game"), as.character(row), sep="")] <- elos$Elo.Rating
    
    # Check for best of 7
    team1_wins <- length(which(series == team1))
    team2_wins <- length(which(series == team2))
    if (team1_wins == 4) {
      first_round <- c(first_round, team1)
      break
    } else if (team2_wins == 4) {
      first_round <- c(first_round, team2)
      break
    }
  }
}

#elo_history
first_round


# 2nd Round - Conference Semifinals (8 Teams): Best-of-7 Series
semi = data.frame(matrix(ncol = 2, nrow = 4))
colnames(semi) <- c("team1", "team2")

# Playoff Schedule
# Western Conference ---- Eastern Conference
semi$team1 <- c(first_round[1], first_round[3], first_round[5], first_round[7])
semi$team2 <- c(first_round[2], first_round[4], first_round[6], first_round[8]) 

second_round <- c()
#row = 1 # For test purposes
#i = 1 # For test purposes
for (row in 1:nrow(semi)) {
  
  # Home Team and Away Team
  team1 <- semi[row, "team1"]
  team2  <- semi[row, "team2"]
  
  # For loop here? for i in 1:7
  series <- c()
  for (i in 1:7) {
    # Pre-match ratings
    x = subset(elos, Team.Name == team1)
    elo.A <- (as.integer(c(x[3])))
    
    y = subset(elos, Team.Name == team2)
    elo.B <- as.integer(c(y[3]))
    
    # Probability of winning
    prob.A <- elo.prob(elo.A, elo.B)
    prob.B <- elo.prob(elo.B, elo.A)
    
    # Best of 7 series sampling
    winner <- sample(c(team1, team2), size=1, prob=c(prob.A, prob.B), replace=TRUE) # size = 7?
    series <- c(series, winner)
    
    # Add winner to list of winners for each matchup
    #first_round <- c(first_round, winner)
    
    if (winner == team1) {
      result = c(1)
    } else if (winner == team2) {
      result = c(0)
    }
    
    # Let's update our ratings
    new_elo <- elo.calc(wins.A = result,
                        elo.A = elo.A, 
                        elo.B = elo.B, 
                        k = 20)
    
    # The results come back as a data.frame
    # with team A's new rating in row 1 / column 1
    # and team B's new rating in row 1 / column 2
    teamA_new_elo <- new_elo[1, 1]
    teamB_new_elo <- new_elo[1, 2]
    
    # We then update the ratings for teams A and B
    # and leave the other teams as they were
    elos <- elos %>%
      mutate(Elo.Rating = if_else(Team.Name == team1, teamA_new_elo,
                           if_else(Team.Name == team2, teamB_new_elo, Elo.Rating)))
    
    # Add updated elos to elo history
    elo_history[, paste(as.character("game"), as.character(row), sep="")] <- elos$Elo.Rating
    
    # Check for best of 7
    team1_wins <- length(which(series == team1))
    team2_wins <- length(which(series == team2))
    if (team1_wins == 4) {
      second_round <- c(second_round, team1)
      break
    } else if (team2_wins == 4) {
      second_round <- c(second_round, team2)
      break
    }
  }
}

#elo_history
second_round

# 3rd Round - Conference Championships (4 Teams): Best-of-7 Series
# At the end of the playoffs, the top two teams play each other in the Conference Finals, to determine the Conference Champions from each side, who then proceed to play in the NBA Finals.
conference = data.frame(matrix(ncol = 2, nrow = 2))
colnames(conference) <- c("team1", "team2")

# Playoff Schedule
# Western Conference ---- Eastern Conference
conference$team1 <- c(second_round[1], second_round[3])
conference$team2 <- c(second_round[2], second_round[4]) 

third_round <- c()
#row = 1 # For test purposes
#i = 1 # For test purposes
for (row in 1:nrow(conference)) {
  
  # Home Team and Away Team
  team1 <- conference[row, "team1"]
  team2  <- conference[row, "team2"]
  
  # For loop here? for i in 1:7
  series <- c()
  for (i in 1:7) {
    # Pre-match ratings
    x = subset(elos, Team.Name == team1)
    elo.A <- (as.integer(c(x[3])))
    
    y = subset(elos, Team.Name == team2)
    elo.B <- as.integer(c(y[3]))
    
    # Probability of winning
    prob.A <- elo.prob(elo.A, elo.B)
    prob.B <- elo.prob(elo.B, elo.A)
    
    # Best of 7 series sampling
    winner <- sample(c(team1, team2), size=1, prob=c(prob.A, prob.B), replace=TRUE) # size = 7?
    series <- c(series, winner)
    
    # Add winner to list of winners for each matchup
    #first_round <- c(first_round, winner)
    
    if (winner == team1) {
      result = c(1)
    } else if (winner == team2) {
      result = c(0)
    }
    
    # Let's update our ratings
    new_elo <- elo.calc(wins.A = result,
                        elo.A = elo.A, 
                        elo.B = elo.B, 
                        k = 20)
    
    # The results come back as a data.frame
    # with team A's new rating in row 1 / column 1
    # and team B's new rating in row 1 / column 2
    teamA_new_elo <- new_elo[1, 1]
    teamB_new_elo <- new_elo[1, 2]
    
    # We then update the ratings for teams A and B
    # and leave the other teams as they were
    elos <- elos %>%
      mutate(Elo.Rating = if_else(Team.Name == team1, teamA_new_elo,
                           if_else(Team.Name == team2, teamB_new_elo, Elo.Rating)))
    
    # Add updated elos to elo history
    elo_history[, paste(as.character("game"), as.character(row), sep="")] <- elos$Elo.Rating
    
    # Check for best of 7
    team1_wins <- length(which(series == team1))
    team2_wins <- length(which(series == team2))
    if (team1_wins == 4) {
      third_round <- c(third_round, team1)
      break
    } else if (team2_wins == 4) {
      third_round <- c(third_round, team2)
      break
    }
  }
}

#elo_history
third_round

# NBA Finals (7-Game Series)
finals = data.frame(matrix(ncol = 2, nrow = 1))
colnames(finals) <- c("team1", "team2")

# Playoff Schedule
# Western Conference ---- Eastern Conference
finals$team1 <- c(third_round[1])
finals$team2 <- c(third_round[2]) 

champion <- c()
#row = 1 # For test purposes
#i = 1 # For test purposes
for (row in 1:nrow(finals)) {
  
  # Home Team and Away Team
  team1 <- semi[row, "team1"]
  team2  <- semi[row, "team2"]
  
  # For loop here? for i in 1:7
  series <- c()
  for (i in 1:7) {
    # Pre-match ratings
    x = subset(elos, Team.Name == team1)
    elo.A <- (as.integer(c(x[3])))
    
    y = subset(elos, Team.Name == team2)
    elo.B <- as.integer(c(y[3]))
    
    # Probability of winning
    prob.A <- elo.prob(elo.A, elo.B)
    prob.B <- elo.prob(elo.B, elo.A)
    
    # Best of 7 series sampling
    winner <- sample(c(team1, team2), size=1, prob=c(prob.A, prob.B), replace=TRUE) # size = 7?
    series <- c(series, winner)
    
    # Add winner to list of winners for each matchup
    #first_round <- c(first_round, winner)
    
    if (winner == team1) {
      result = c(1)
    } else if (winner == team2) {
      result = c(0)
    }
    
    # Let's update our ratings
    new_elo <- elo.calc(wins.A = result,
                        elo.A = elo.A, 
                        elo.B = elo.B, 
                        k = 20)
    
    # The results come back as a data.frame
    # with team A's new rating in row 1 / column 1
    # and team B's new rating in row 1 / column 2
    teamA_new_elo <- new_elo[1, 1]
    teamB_new_elo <- new_elo[1, 2]
    
    # We then update the ratings for teams A and B
    # and leave the other teams as they were
    elos <- elos %>%
      mutate(Elo.Rating = if_else(Team.Name == team1, teamA_new_elo,
                           if_else(Team.Name == team2, teamB_new_elo, Elo.Rating)))
    
    # Add updated elos to elo history
    elo_history[, paste(as.character("game"), as.character(row), sep="")] <- elos$Elo.Rating
    
    # Check for best of 7
    team1_wins <- length(which(series == team1))
    team2_wins <- length(which(series == team2))
    if (team1_wins == 4) {
      champion <- c(champion, team1)
      break
    } else if (team2_wins == 4) {
      champion <- c(champion, team2)
      break
    }
  }
}

#elo_history
# CHAMPION
champion

# All stages
first_round
second_round
third_round
champion

# Plot elo_history

matplot(t(elo_history[,-c(1)]), type="l")

df_melted = melt(elo_history, id.vars='Team.Name')
```

### The Remaining 2019-2020 Regular Season

Since the 2019-20 season was suspended before the end of the regular season, there were still more games to be played (about a month remained in the regular season). Fortunately, we were able to scrape the remaining schedule for the regular season for every game that was set to take place.

The regular season would have originally lasted through mid-April. Since we have all the matchups, we can run these teams through a simulation to compete based on probability using their Elo ratings. This involved iterating over the dataset, retrieving each teams Elo rating to calculate their probability of winning/losing, and then pulling a random sample as the winner. After the winner was found, the Elo ratings were then updated to reflect the outcome of this matchup.

Repeating this procedure for every game in the remaining regular season schedule resulted in the final Elo scores for every team at the beginning of the Playoffs.


### The 2019-2020 NBA Playoffs

In the NBA Playoffs, the top 8 teams in terms of win/loss record from each Conference (Eastern Conference & Western Conference) advance to the Playoffs. The teams are then seeded (ranked) based on these win/loss records, and matched accordingly for the playoffs. This means the #1 seed plays the #8 seed, the #2 seed plays the #7 seed, the #3 seed plays the #6 seed, and the #4 seed plays the #5 seed in each conference. Since the seedings are based on win/loss, we found it appropriate to seed the teams based on Elo ratings (which is an outcome of win/loss). This also helps to avoid the complicated process should two teams have the same win loss record (there is a significantly lower probability two teams in this case have the exact same Elo rating). We simulated each matchup of the Playoffs to determine which teams advanced to ultimately identify the NBA Champions for the 2019-20 NBA season.



## Predicting the 2019-20 NBA Season Award Winners

Another interesting part of any NBA season is the awards given to the players and teams based on their regular season performances. Some key awards that catch headlines every year include Most Valuable Player (MVP) and Defensive Player of the Year (DPOY). In addition to predicting the end-of-season standings, we decided that any analysis of the remainder of the 2019-20 NBA season would be incomplete unless it discussed award winners in the major categories. As avid basketball fans, this idea resonated with us so we decided to scientifically predict who would ultimately win the MVP and DPOY awards.

In order to predict award winners at the end of the season, we needed to predict the leaders of some of the crucial statistical categories at the end of the season. To predict these players, we analyzed some significant statistics and identified the optimal regression model to predict these statistics. Some of the statistics we utilized in building this model include true shooting percentage (TS%), total rebound percentage (TRB%), assist percentage (AST%), and block percentage (BLK%) among 22 total recorded categories. For additional information on the exact statistics that were used in these predictions, refer to Table 3 (Appendix).

Accordingly, we examined different types of regression models in order to identify which type of model best predicted some of the major statistics. These include win shares (WS), value over replacement player (VORP), player efficiency rating (PER), usage percentage (USG%), offensive box plus/minus (OBPM), and defensive box plus/minus (DBPM). For more detailed explanations of the significance of each of these statistics, refer to Table 3 (Appendix).

To identify the best prediction model, we first predicted WS from the current 2019-20 season statistics using 4 different regression models: linear, lasso, ridge, and logistic. We measured the performance of every model with the actual WS values for each player using RMSE (root mean squared error) to determine which had the least error where smaller RMSE values indicated higher accuracy. In order to reduce Monte Carlo variability, we used 200 repeated random samples of the data for each model to find the true RMSE values.

We then used this to predict the MVP and DPOY by looking at the leaders at the end of the season in WS, VORP, PER, USG%, OBPM, and DBPM because these categories carried significant weighting in determing the respective awards. In order to produce statistics that would reflect the end-of-season data, we updated each player's stats based on their team, position, schedule matchups, and usage percentage. We weighted each of these features by category and used the current player statistics to simulate the expected statistics for every player at the end of the 2019-20 season. We chose these specific features because a player's team and schedule can heavily influence their output, the position they play directly affects which stats are affected, and their usage percentage indicates how heavily their team relies on that specific player (which correlates to more playing time). For example, a point guard is more likely to focus on assists, a shooting guard is more likely to focus on shooting percentage and 3-point attempt percentage, and a center is more likely to focus on rebounds and blocks. Similarly, a player with a high usage percentage will be instrumental to the team and will thus receive more playing time to add to their stat lines.

Another important note to consider is that some of the statistical categories are related to other categories. For example, offensive win shares (OWS) and defensive win shares (DWS) are directly related to overall win shares (WS) because they are simply more specific aspects of the general WS category. In order to account for these confounding variables and ensure that the predictions were accurately estimated from all of the relevant data, we made sure to exclude the respective confounding variables when running each regression model. For instance, we excluded BPM when running regression models on OBPM and DBPM for the same reason.



# Results

```{r calculate_elo, include=FALSE}
nbateams <- data.frame(team=union(season2019_2020$home_team_name, season2019_2020$visitor_team_name))
nbateams <- nbateams %>% mutate(elo=1500)
nbateams

historical_elo <- data.frame(team = nbateams$team)
historical_elo <- historical_elo %>% mutate(elo=1500)

head(season2019_2020)
season2019_2020$home_team_wins

#Copy and paste season data.frame into loop (seq and match) to update elo for consecutive seasons
for (i in seq(nrow(season2019_2020))) {
  match <- season2019_2020[i, ]
  
  #Pre-match ratings
  teamA_elo <- subset(nbateams, team==match$home_team_name)$elo
  teamB_elo <- subset(nbateams, team==match$visitor_team_name)$elo
  
  #Update our ratings
  new_elo <- elo.calc(wins.A = match$home_team_wins,
                      elo.A = teamA_elo,
                      elo.B = teamB_elo,
                      k = 20)
  
  #Results reported as data.frame
  #Team A's new rating in row1/column1
  #Team B's new rating in row1/column2
  new_elo
  teamA_new_elo <- new_elo[1,1]
  teamB_new_elo <- new_elo[1,2]
  
  #Update the ratings for Teams A and B and leave other teams as they were
  nbateams <- nbateams %>%
    mutate(elo = if_else(team==match$home_team_name, teamA_new_elo,
                         if_else(team==match$visitor_team_name, teamB_new_elo, elo)))
}

options(digits=8)

nbateams %>%
  arrange(-elo)

avg_season_elo = 1505

nbateams <- nbateams %>% mutate(elo=0.75*elo+.25*avg_season_elo)

nbateams <- nbateams %>%
  arrange(-elo)

names(nbateams)[names(nbateams) == "team"] <- "Team"
names(nbateams)[names(nbateams) == "elo"] <- "Elo Rating"
```

```{r elo_ratings, fig.pos = "H", echo=FALSE, comment=NA}
kable(list(nbateams[1:15,], nbateams[16:30,]), caption = "Elo Ratings for Every NBA Team (Descending)")
```

```{r regression_models, include=FALSE}
player_stats <- data.frame(player_stats)
player_stats <- player_stats[!(player_stats$Tm=="TOT"),]
player_stats <- player_stats[(player_stats$G>=25 & player_stats$MP>=1200),]


# rmse function
rmse = function(y, yhat) {
  sqrt(mean((y - yhat)^2, na.rm=TRUE))
}

# variables that control how long the program takes to run
num_splits = 200
#k_limit = 20

#model 1: linear regression model (RMSE)
#80% training data, 20% test data
n = nrow(player_stats)
n_train = round(0.8*n)  # round to nearest integer
n_test = n - n_train

#200 different random splits
lm_vals = do(num_splits)*{
  
  # re-split into train and test cases with the same sample sizes
  train_cases = sample.int(n, n_train, replace=FALSE)
  test_cases = setdiff(1:n, train_cases)
  on_train = player_stats[train_cases, 6:27]
  on_test = player_stats[test_cases, 6:27]
  
  linearModel = lm(WS ~ (. - WS.48 - OWS - DWS), data=on_train)
  linearModelInteractions = lm(WS ~ (. - WS.48 - OWS - DWS)^2, data=on_train)
  
  # Predictions out of sample + convert to binary
  y_test = predict(linearModel, on_test)
  y_test_2 = predict(linearModelInteractions, on_test)
  
  c(rmse(y_test, on_test$WS),rmse(y_test_2, on_test$WS))
}
lm_avg = unname(colMeans(lm_vals))
lm_avg


#models 2,3: lasso regression/ridge regression (RMSE)
vals_lr_rr = do(num_splits)*{
  
  # re-split into train and test cases with the same sample sizes
  train_cases = sample.int(n, n_train, replace=FALSE)
  test_cases = setdiff(1:n, train_cases)
  on_train = player_stats[train_cases, 6:27]
  on_test = player_stats[test_cases, 6:27]
  
  temp_train = model.matrix.lm(WS ~ (. - WS.48 - OWS - DWS), data = on_train, na.action=na.pass)
  temp_test = model.matrix.lm(WS ~ (. - WS.48 - OWS - DWS), data = on_test, na.action=na.pass)
  x_train = temp_train[complete.cases(temp_train),]
  y_train = on_train$WS[complete.cases(temp_train)]
  x_test = temp_test[complete.cases(temp_test),]
  y_test = on_test$WS[complete.cases(temp_test)]
  
  # lasso regression
  cv_fit_l = cv.glmnet(x_train, y_train, family="gaussian", alpha = 1)
  # ridge regression
  cv_fit_r = cv.glmnet(x_train, y_train, family="gaussian", alpha = 0)
  
  opt_lambda_l = cv_fit_l$lambda.min
  opt_lambda_r = cv_fit_r$lambda.min
  
  y_pred_l = predict(cv_fit_l$glmnet.fit, s = opt_lambda_l, newx = x_test)
  y_pred_r = predict(cv_fit_r$glmnet.fit, s = opt_lambda_r, newx = x_test)
  
  c(rmse(y_pred_l, y_test), rmse(y_pred_r, y_test))
}
lr_model_avg = min(vals_lr_rr[,1])
rr_model_avg = min(vals_lr_rr[,2])
lr_model_avg
rr_model_avg


#model 4: logistic regression
vals_logm = do(num_splits)*{
  # re-split into train and test cases with the same sample sizes
  train_cases = sample.int(n, n_train, replace=FALSE)
  test_cases = setdiff(1:n, train_cases)
  on_train = player_stats[train_cases, 6:27]
  on_test = player_stats[test_cases, 6:27]
  
  logitModel = glm(WS ~ (. - WS.48 - OWS - DWS), data=on_train, family=gaussian, maxit = 100)
  logitModelInteractions = glm(WS ~ (. - WS.48 - OWS - DWS)^2, data=on_train, family=gaussian, maxit = 100)
  
  # Predictions out of sample + convert to binary
  y_test = predict(logitModel, on_test)
  y_test_2 = predict(logitModelInteractions, on_test)
  
  c(rmse(y_test, on_test$WS), rmse(y_test_2, on_test$WS))
}
logm_vals = unname(colMeans(vals_logm))
```

```{r reg_model_rmse, include=FALSE, comment=NA, warning=FALSE}
cat("MODEL SUCCESS:")
cat("1) LINEAR REGRESSION MODEL (without interactions) - RMSE:", lm_avg[1])
cat("1) LINEAR REGRESSION MODEL (with interactions) - RMSE:", lm_avg[2])
cat("2) LASSO REGRESSION - RMSE:", lr_model_avg[1])
print("coefficients for lasso regression:")
print(coef(cv_fit_l$glmnet.fit,s = cv_fit_l$lambda.min))
cat("3) RIDGE REGRESSION - RMSE:", rr_model_avg[1])
#print("coefficients for ridge regression:")
#print(coef(cv_fit_r$glmnet.fit,s = cv_fit_r$lambda.min))
cat("4) LOGISTIC REGRESSION (without interactions) - RMSE:", logm_vals[1])
cat("4) LOGISTIC REGRESSION (with interactions) - RMSE:", logm_vals[2])
```


First, we calculated the Elo ratings for each team for the games played so far in the 2019-20 season. As explained earlier, we incorporated 25% of the previous season's Elo ratings with 75% of this season's current Elo ratings. To better visualize how each team's Elo rating is updated throughout the season, Figure \ref{fig:current_elo} shows the Elo rating of every team since the opening of the 2019-20 season for all games that have been played (prior to the suspension). This plot shows how the Elo rating can fluctuate over the course of a season and how the better teams tend to have an upward trajectory to build momentum towards clinching a playoff berth. We included a plot faceted by Conference because it better highlights which teams are likely to secure playoff seeding since the Playoffs matchups are organized by Conference.

```{r, echo=FALSE, fig.align='center', fig.cap="\\label{fig:current_elo}Elo Rating Over 2019-20 for Each NBA Team by Conference"}
ggplot(elo_df, aes(x=Games.Played, y=Elo.Rating, color=Team)) + geom_line() + facet_grid(elo_df$Conference~.)
```

```{r echo=FALSE, eval=FALSE, out.width='100%', fig.width = 8, fig.height = 5, fig.align='center', fig.cap="\\label{fig:current_elo}Elo Rating Over 2019-20 for Each NBA Team by Conference", comment=NA, warning=FALSE}
include_graphics('./CurrentEloRating.png')
```

We then predicted how the remaining of the regular season would play out and the standings of the teams at the end of the season. Table 1 shows the Elo ratings we predicted for each team at the end of the season. Noticeably, the teams who had already secured Playoff berths before the season suspension have higher Elo rating predictions (as is to be expected).

Using the method explained above to predict the Playoff matchups, we were able to simulate the games for the Playoffs. This is how the first-round playoff matchups turned out:


&nbsp;


> **Eastern Conference:** Milwaukee vs. Orlando, Toronto vs. Brooklyn, Boston vs. Philadelphia, Miami vs. Indiana

> **Western Conference:** LA Lakers vs. Memphis, LA Clippers vs. Dallas, Denver vs. Houston, Utah vs. Oklahoma


&nbsp;

The same process for the regular season was applied to these matchups with a couple of tweaks. This simulation was a best-of-7 tournament (as are all playoffs and finals matches). As a result, we had to simulate the games until a team reached 4 wins. The teams who won and advanced to the second round are as follows:

&nbsp;


> **Eastern Conference:** Milwaukee, Toronto, Philadelphia, Miami

> **Western Conference:** LA Lakers, LA Clippers, Houston, Utah


&nbsp;

The second round is the same process as the first round, except this time, the top 4 teams of each conference advance, meaning that the other 4 teams are eliminated. The second round is also known as the Conference Semifinals, that is, the winners of these games advance to their respective Conference Finals to compete for the Conference title. The second round matchups are shown below:

&nbsp;


> **Eastern Conference:** Milwaukee vs. Miami, Toronto vs. Philadelphia

> **Western Conference:** LA Lakers vs. Utah, LA Clippers vs. Houston


&nbsp;

with the winners being:

&nbsp;


> **Eastern Conference:** Milwaukee, Toronto

> **Western Conference:** LA Lakers, LA Clippers


&nbsp;

The last round of the playoffs is the third round, also referred to as the Conference Finals. The top two teams from both the Western and Eastern Conference compete for the top spot in their respective Conference. The matchup for the Conference Finals was predicted to feature the heavy weight teams from both Conferences with the following matchups:

&nbsp;


> **Eastern Conference:** Milwaukee vs. Toronto

> **Western Conference:** LA Lakers vs. LA Clippers


&nbsp;

Again, these teams were put through a best-of-7 simulation, in which the following winners emerged:

&nbsp;


> **Eastern Conference:** Milwaukee

> **Western Conference:** LA Lakers


&nbsp;

Now that we had predicted our initial 16 Playoff teams down to the Conference Champions, we set the stage for the NBA Finals matchup between the Milwaukee Bucks and the Los Angeles Lakers. Both teams featured several superstars and were favored to meet in the NBA Finals by several sports analysts. **Simulating this exciting matchup, our simulation predicted that the NBA Championship would be won by the Los Angeles Lakers**.

```{r first_round, eval=FALSE, include=FALSE}
# First Round
kable(playoffs)
kable(first_round)
```

```{r second_round, eval=FALSE,  include=FALSE}
# Second Round
kable(semi)
kable(second_round)
```

```{r third_round, eval=FALSE,  include=FALSE}
# Third Round
kable(conference)
kable(third_round)
```

```{r final_round, eval=FALSE, include=FALSE}
# NBA Finals
kable(finals)
kable(champion)
```

Figure \ref{fig:pred_elo} shows how the Elo ratings for each NBA team changed throughout the end of the regular season as well as both the Playoffs and Finals. A line that remains flat for a short period of time represents the Elo rating remaining constant due to the fact of not playing at that instance. The changes to Elo rating come after they have played a game.

```{r, echo=FALSE, comment=NA, warning=FALSE}
# Plot elo_history

#matplot(t(elo_history[,-c(1)]), type="l")
```

```{r, results='hide', echo=FALSE, warning=FALSE, error=FALSE, message=FALSE, out.width='100%', fig.width = 8, fig.height = 5, fig.align='center', fig.cap="\\label{fig:pred_elo}Elo Rating for End of Regular Season and Playoffs"}
ggplot(df_melted, aes(x = variable, y = value)) + 
  geom_line(aes(color = Team.Name, group = Team.Name)) +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  ggtitle("Elo Rating for End of Regular Season") +
  xlab("Games") + ylab("Elo Rating")

# Drawbacks
# Best of 7 series do not account for HCA, too complicated to incorporate
# Simulation is random and you could get different outcomes (create a list and find most common answer?)
# Elo is based only off win/loss, HCA, margin, does not account for roster changes, injuries, and other factors
```

```{r echo=FALSE, eval=FALSE, out.width='100%', fig.width = 8, fig.height = 5, fig.align='center', fig.cap="\\label{fig:pred_elo}Elo Rating for End of Regular Season and Playoffs", comment=NA, warning=FALSE}
include_graphics('./EloPredicted.png')
```

In addition to simulating how the 2019-20 NBA season and Playoffs would have ended, we tested several regression models to determine the best model to predict end-of-season WS. By testing linear, lasso, ridge, and logistic regression models, found that the lasso model provided the lowest RMSE value (`r lr_model_avg[1]`) with the linear model (`r lm_avg[1]`) and logistic models (`r logm_vals[1]`) providing slightly higher RMSE values.

```{r pred_stat_leaders, echo=FALSE, fig.align='center', fig.cap="\\label{fig:pred_stat_leaders}End-of-Season Predicted Stat Leaders with Logistic Regression Model", fig.height=2, fig.show='hold', fig.width=3, warning=FALSE, comment=NA, out.width='.49\\linewidth'}
# Update player stats for end-of-season 2019-20

player_stats_update <- data.frame(player_stats)

player_stats_update$AST.[player_stats_update$Pos=="PG"] <- player_stats_update$AST.[player_stats_update$Pos=="PG"] + 0.5
player_stats_update$AST.[player_stats_update$Pos=="SG"] <- player_stats_update$AST.[player_stats_update$Pos=="SG"] + 0.1
player_stats_update$AST.[player_stats_update$Pos=="SF"] <- player_stats_update$AST.[player_stats_update$Pos=="SF"] - 0.1
player_stats_update$AST.[player_stats_update$Pos=="PF"] <- player_stats_update$AST.[player_stats_update$Pos=="PF"] + 0.2
player_stats_update$AST.[player_stats_update$Pos=="C"] <- player_stats_update$AST.[player_stats_update$Pos=="C"] - 0.2

player_stats_update$ORB.[player_stats_update$Pos=="PG"] <- player_stats_update$ORB.[player_stats_update$Pos=="PG"] - 0.1
player_stats_update$ORB.[player_stats_update$Pos=="SG"] <- player_stats_update$ORB.[player_stats_update$Pos=="SG"] - 0.1
player_stats_update$ORB.[player_stats_update$Pos=="SF"] <- player_stats_update$ORB.[player_stats_update$Pos=="SF"] + 0.3
player_stats_update$ORB.[player_stats_update$Pos=="PF"] <- player_stats_update$ORB.[player_stats_update$Pos=="PF"] + 0.5
player_stats_update$ORB.[player_stats_update$Pos=="C"] <- player_stats_update$ORB.[player_stats_update$Pos=="C"] + 0.7

player_stats_update$DRB.[player_stats_update$Pos=="PG"] <- player_stats_update$DRB.[player_stats_update$Pos=="PG"] - 0.1
player_stats_update$DRB.[player_stats_update$Pos=="SG"] <- player_stats_update$DRB.[player_stats_update$Pos=="SG"] - 0.1
player_stats_update$DRB.[player_stats_update$Pos=="SF"] <- player_stats_update$DRB.[player_stats_update$Pos=="SF"] + 0.3
player_stats_update$DRB.[player_stats_update$Pos=="PF"] <- player_stats_update$DRB.[player_stats_update$Pos=="PF"] + 0.5
player_stats_update$DRB.[player_stats_update$Pos=="C"] <- player_stats_update$DRB.[player_stats_update$Pos=="C"] + 0.7

player_stats_update$TRB.[player_stats_update$Pos=="PG"] <- player_stats_update$TRB.[player_stats_update$Pos=="PG"] - 0.2
player_stats_update$TRB.[player_stats_update$Pos=="SG"] <- player_stats_update$TRB.[player_stats_update$Pos=="SG"] - 0.2
player_stats_update$TRB.[player_stats_update$Pos=="SF"] <- player_stats_update$TRB.[player_stats_update$Pos=="SF"] + 0.4
player_stats_update$TRB.[player_stats_update$Pos=="PF"] <- player_stats_update$TRB.[player_stats_update$Pos=="PF"] + 0.6
player_stats_update$TRB.[player_stats_update$Pos=="C"] <- player_stats_update$TRB.[player_stats_update$Pos=="C"] + 0.8

player_stats_update$BLK.[player_stats_update$Pos=="PG"] <- player_stats_update$BLK.[player_stats_update$Pos=="PG"] - 0.2
player_stats_update$BLK.[player_stats_update$Pos=="SG"] <- player_stats_update$BLK.[player_stats_update$Pos=="SG"] - 0.2
player_stats_update$BLK.[player_stats_update$Pos=="SF"] <- player_stats_update$BLK.[player_stats_update$Pos=="SF"] + 0.2
player_stats_update$BLK.[player_stats_update$Pos=="PF"] <- player_stats_update$BLK.[player_stats_update$Pos=="PF"] + 0.3
player_stats_update$BLK.[player_stats_update$Pos=="C"] <- player_stats_update$BLK.[player_stats_update$Pos=="C"] + 0.5

player_stats_update$TS.[player_stats_update$Pos=="PG"] <- player_stats_update$TS.[player_stats_update$Pos=="PG"] + 0.01
player_stats_update$TS.[player_stats_update$Pos=="SG"] <- player_stats_update$TS.[player_stats_update$Pos=="SG"] + 0.02
player_stats_update$TS.[player_stats_update$Pos=="SF"] <- player_stats_update$TS.[player_stats_update$Pos=="SF"] + 0.02
player_stats_update$TS.[player_stats_update$Pos=="PF"] <- player_stats_update$TS.[player_stats_update$Pos=="PF"] + 0.01
player_stats_update$TS.[player_stats_update$Pos=="C"] <- player_stats_update$TS.[player_stats_update$Pos=="C"] + 0.02


player_stats_update$WS[player_stats_update$Tm=="MIL"] <- player_stats_update$WS[player_stats_update$Tm=="MIL"] + 0.4
player_stats_update$WS[player_stats_update$Tm=="LAL"] <- player_stats_update$WS[player_stats_update$Tm=="LAL"] + 0.4
player_stats_update$WS[player_stats_update$Tm=="TOR"] <- player_stats_update$WS[player_stats_update$Tm=="TOR"] + 0.3
player_stats_update$WS[player_stats_update$Tm=="LAC"] <- player_stats_update$WS[player_stats_update$Tm=="LAC"] + 0.25
player_stats_update$WS[player_stats_update$Tm=="OKC"] <- player_stats_update$WS[player_stats_update$Tm=="OKC"] + 0.2


player_stats_update$WS[player_stats_update$USG.>=25.0] <- player_stats_update$WS[player_stats_update$USG.>=25.0] + 1.5
player_stats_update$WS.48[player_stats_update$USG.>=25.0] <- player_stats_update$WS.48[player_stats_update$USG.>=25.0] + 0.015



# Re-sample train/test splits
train_cases = sample.int(n, n_train, replace=FALSE)
test_cases = setdiff(1:n, train_cases)
on_train = player_stats_update[train_cases, 6:27]
on_test = player_stats_update[test_cases, 6:27]




logitModelWS = glm(WS ~ (. - WS.48 - OWS - DWS), data=on_train, family=gaussian, maxit = 100)

predicted_WS = predict(logitModelWS, player_stats_update[,6:27])

predictions_WS <- data.frame(player_stats_update$Player, predicted_WS)
predictions_WS <- predictions_WS %>%
  arrange(-predicted_WS)
#head(predictions_WS)

names(predictions_WS)[names(predictions_WS) == "player_stats_update.Player"] <- "Player"
names(predictions_WS)[names(predictions_WS) == "predicted_WS"] <- "Predicted WS"

#kable(predictions_WS[1:5,], caption = "Predicted WS Leaders at the End of the Regular Season")




logitModelVORP = glm(VORP ~ (. - WS - WS.48 - OWS - DWS), data=on_train, family=gaussian, maxit = 100)

predicted_VORP = predict(logitModelVORP, player_stats_update[,6:27])

predictions_VORP <- data.frame(player_stats_update$Player, predicted_VORP)
predictions_VORP <- predictions_VORP %>%
  arrange(-predicted_VORP)
#head(predictions_VORP)

names(predictions_VORP)[names(predictions_VORP) == "player_stats_update.Player"] <- "Player"
names(predictions_VORP)[names(predictions_VORP) == "predicted_VORP"] <- "Predicted VORP"

#kable(predictions_VORP[1:5,], caption = "Predicted VORP Leaders at the End of the Regular Season")




logitModelPER = glm(PER ~ (. - WS - WS.48 - OWS - DWS), data=on_train, family=gaussian, maxit = 100)

predicted_PER = predict(logitModelPER, player_stats_update[,6:27])

predictions_PER <- data.frame(player_stats_update$Player, predicted_PER)
predictions_PER <- predictions_PER %>%
  arrange(-predicted_PER)
#head(predictions_PER)

names(predictions_PER)[names(predictions_PER) == "player_stats_update.Player"] <- "Player"
names(predictions_PER)[names(predictions_PER) == "predicted_PER"] <- "Predicted PER"

#kable(predictions_PER[1:5,], caption = "Predicted PER Leaders at the End of the Regular Season")




logitModelUSG = glm(USG. ~ (. - WS - WS.48 - OWS - DWS), data=on_train, family=gaussian, maxit = 100)

predicted_USG = predict(logitModelUSG, player_stats_update[,6:27])

predictions_USG <- data.frame(player_stats_update$Player, predicted_USG)
predictions_USG <- predictions_USG %>%
  arrange(-predicted_USG)
#head(predictions_USG)

names(predictions_USG)[names(predictions_USG) == "player_stats_update.Player"] <- "Player"
names(predictions_USG)[names(predictions_USG) == "predicted_USG"] <- "Predicted USG%"

#kable(predictions_USG[1:5,], caption = "Predicted USG% Leaders at the End of the Regular Season")




logitModelOBPM = glm(OBPM ~ (. - WS - WS.48 - OWS - DWS - BPM), data=on_train, family=gaussian, maxit = 100)

predicted_OBPM = predict(logitModelOBPM, player_stats_update[,6:27])

predictions_OBPM <- data.frame(player_stats_update$Player, predicted_OBPM)
predictions_OBPM <- predictions_OBPM %>%
  arrange(-predicted_OBPM)
#head(predictions_OBPM)

names(predictions_OBPM)[names(predictions_OBPM) == "player_stats_update.Player"] <- "Player"
names(predictions_OBPM)[names(predictions_OBPM) == "predicted_OBPM"] <- "Predicted OBPM"

#kable(predictions_OBPM[1:5,], caption = "Predicted OBPM Leaders at the End of the Regular Season")




logitModelDBPM = glm(DBPM ~ (. - WS - WS.48 - OWS - DWS - BPM), data=on_train, family=gaussian, maxit = 100)

predicted_DBPM = predict(logitModelDBPM, player_stats_update[,6:27])

predictions_DBPM <- data.frame(player_stats_update$Player, predicted_DBPM)
predictions_DBPM <- predictions_DBPM %>%
  arrange(-predicted_DBPM)
#head(predictions_DBPM)

names(predictions_DBPM)[names(predictions_DBPM) == "player_stats_update.Player"] <- "Player"
names(predictions_DBPM)[names(predictions_DBPM) == "predicted_DBPM"] <- "Predicted DBPM"

#kable(predictions_DBPM[1:5,], caption = "Predicted DBPM Leaders at the End of the Regular Season")


kable(list(predictions_WS[1:5,], predictions_VORP[1:5,], predictions_PER[1:5,], predictions_USG[1:5,], predictions_OBPM[1:5,], predictions_DBPM[1:5,]), caption = "End-of-Season 2019-20 Predicted Stat Leaders with Logistic Regression Model")
```

We then predicted the season leaders for the various principal categories of WS, VORP, PER, OBPM, and DBPM. We utilized a logistic regression model for predicting the stat leaders due to its relative simplicity and clarity. We verified that this logistic regression model was appropriate by measuring its RMSE values and plotting predicted end-of-season statistics for each player for every category as well as the actual vs. predicted statistics for each category for the current 2019-20 season data (Figure \ref{fig:pred_stat_plots}). The plots in Figure \ref{fig:pred_stat_plots} indicate the end-of-season statistic value for each category based on a player's current 2019-20 season data for that statistic. The red lines indicate the value that a player can expect to end the season with for every value along the $x$-axis (which represents the player's current statistic for that category). These plots verify that the predicted stats fall within a very small margin of the actual stats and thus have small residual values (since a majority of this season's games have already been played). Also, there is a very minor shift in some of the data points (i.e. VORP) because the last month of games would likely change some of these player statistics since teams with guaranteed playoff seeding are more likely to rest their star players.

Using these accumulated season statistics, we determined the end-of-season statistics by updating each players' stat lines based on team, position, schedule matchups, and usage percentage stats as explained in detail in the Methods section. The end-of-season stat leaders for each of the main categories is shown in Table 2. We verified these predictions by limiting the qualifiers for each category and comparing with each player's previous performance history. We narrowed the pool of players down by only considering players with more than 25 games played and 1200 minutes played because this reflects the criteria that the NBA Season Awards use to nominate qualifying players. By inspecting the top five players in each category, we noticed several household names and early season favorites for MVP and DPOY including Giannis Antetokounmpo, James Harden, LeBron James, and Anthony Davis.

In regards to determining the MVP nominees, the categories of WS, VORP, PER, and OBPM are significant because they constitute the most holistic perspective of each player's performance and are oriented around the 3 key factors for MVP: overall team success, value of the player to the team, and on-court presence. These 3 central components are acutely summarized in these statistics, so we used a point-based system to determine the top 3 nominees for MVP by looking at each player's rank within each category. In regards to determining the DPOY nominees, the categories of DBPM, USG%, PER, and VORP are significant because they constitute a comprehensive view of a player's defensive contributions. A DPOY nominee is typically a leader or near the top of several of these statistics, so these categories are a good representation of who is likely to be nominated for DPOY.

Giannis Antetokounmpo led an overwhelming majority of the statistics (WS, VORP, PER, USG%, DBPM). Not only did he lead each of these categories in our end-of-season predictions, he was also in the top three players for the other statistics, including OBPM shown in Table 2. **Due to this dominant stat line, we reasoned that our model predicted that Giannis Antetokounmpo would win both the MVP and DPOY awards.** This is an eye-catching prediction since this feat has only been accomplished twice before in the history of the NBA. From these projections, the reasonable runner-up for MVP was James Harden. For DPOY, these results show that the clear runner-up was Anthony Davis.

```{r echo=FALSE, fig.width = 5, fig.height = 3, fig.align='center', out.width='.49\\linewidth', fig.show='hold', fig.cap="\\label{fig:pred_stat_plots}Predictions of Key Statistics with Logistic Regression Model", fig.pos = "H", comment=NA, warning=FALSE}
ggplot() +
  geom_point(data=player_stats_update[,6:27],aes(x = WS, y = predicted_WS ), color="black") + 
  geom_line(data=player_stats[,6:27],aes(x = WS, y = WS ), color="red") + 
  xlab("Actual WS") + 
  ylab("Predicted WS") + 
  ggtitle("Actual WS vs. Predicted WS")

ggplot() +
  geom_point(data=player_stats_update[,6:27],aes(x = VORP, y = predicted_VORP ), color="black") + 
  geom_line(data=player_stats[,6:27],aes(x = VORP, y = VORP ), color="red") + 
  xlab("Actual VORP") + 
  ylab("Predicted VORP") + 
  ggtitle("Actual VORP vs. Predicted VORP")

ggplot() +
  geom_point(data=player_stats_update[,6:27],aes(x = PER, y = predicted_PER ), color="black") + 
  geom_line(data=player_stats[,6:27],aes(x = PER, y = PER ), color="red") + 
  xlab("Actual PER") + 
  ylab("Predicted PER") + 
  ggtitle("Actual PER vs. Predicted PER")

ggplot() +
  geom_point(data=player_stats_update[,6:27],aes(x = USG., y = predicted_USG ), color="black") + 
  geom_line(data=player_stats[,6:27],aes(x = USG., y = USG. ), color="red") + 
  xlab("Actual USG%") + 
  ylab("Predicted USG%") + 
  ggtitle("Actual USG% vs. Predicted USG%")

ggplot() +
  geom_point(data=player_stats_update[,6:27],aes(x = OBPM, y = predicted_OBPM ), color="black") + 
  geom_line(data=player_stats[,6:27],aes(x = OBPM, y = OBPM ), color="red") + 
  xlab("Actual OBPM") + 
  ylab("Predicted OBPM") + 
  ggtitle("Actual OBPM vs. Predicted OBPM")

ggplot() +
  geom_point(data=player_stats_update[,6:27],aes(x = DBPM, y = predicted_DBPM ), color="black") + 
  geom_line(data=player_stats[,6:27],aes(x = DBPM, y = DBPM ), color="red") + 
  xlab("Actual DBPM") + 
  ylab("Predicted DBPM") + 
  ggtitle("Actual DBPM vs. Predicted DBPM")
```



# Conclusion

Through our analysis of the 2019-20 NBA season, we were able to analyze and predict several important aspects of the season had it continued as per schedule. We were first able to calculate the Elo rating for each team through the games that had already been played in the 2019-20 season. This was insightful because it showed us how each team performed over the course of the season. This would be interesting to GMs and sports analysts alike because it shows how a team can increase performance as the season goes on, remains at stagnant production (wins and losses about equal), or whether the team was affected by a major, unexpected hurdle in the middle of a season (i.e. injuries to role players, trades, etc.).

Using this understanding, we predicted how the season would end by simulating the remaining games and producing Elo ratings for the end of the season. This would be useful for a team manager or coach to evaluate the team's overall season performance in order to compare to previous seasons data and determine whether any changes need to be implemented, such as trading for certain positional players or releasing players that were ineffective.

In a similar manner, we predicted how the postseason Playoffs would shake out in terms of seeding, matchups, and winners. We ran another comparable prediction model using the end-of-season predicted Elo ratings for each team. We ran these matchups in best-of-7 scenarios using the Elo proability factors explained above to identify which teams advanced. After running our predictions over numerous iterations, we predicted that the Western Conference Finals would feature a matchup between the LA Lakers and the LA Clippers and the Eastern Conference Finals would feature a matchup between the Milwaukee Bucks and the Toronto Raptors. Ultimately, the LA Lakers and Milwaukee Bucks emerged victorious for a Finals clash with the LA Lakers being crowned the predicted NBA Champions for 2019-20.

Not only did we predict how the season would end, we also used regression prediction models (linear, lasso, ridge, and logistic) to predict the end-of-season stat leaders for various crucial categories that are used to determine the MVP and DPOY. We found that the lasso regression model produced the lowest RMSE values when predicting WS based on the current 2019-20 data. Since the logistic regression model is easier to interpret and produced only a slightly higher RMSE value, we used the logistic regression model to predict the remaining key statistics (VORP, PER, USG%, OBPM, DBPM) for the end of the season. The projected leaders at the end of the season for each of these categories is depicted in Table 2. From these predictions, we found that Giannis Antetokounmpo is projected to win both the MVP and the DPOY with James Harden and Anthony Davis coming in second for each category, respectively. This is an noteworthy prediction because winning two of the most prestigious awards in basketball is an amazing testament to the player's performance this season. This information would be useful to GMs, franchise front offices, and the players' agents. For example, the franchise front offices could use this type of prediction to help build the best contract for the star players that would also benefit the team. Additionally, this would be useful to the players' agents because it would help them argue for favorable contract negotiations for their clients.

Overall, these types of predictions of season outcomes, Playoff matchups, and season award winners could immensely help teams with identifying how to improve for upcoming seasons or how to better prepare their players for one-on-one matchups against certain teams. Not only did this project yield entertaining and interesting results for the 2019-20 season, it could be further extended to future seasons when teams are trying to predict how to negotiate contracts for certain players.



## Drawbacks of the Elo Rating Predictions

Although Elo ratings are simple and intuitive, this is both a blessing and a curse. Given the performance, Elo rating should be commended, however, this does not mean it should be used to support addictive sports gambling habits because it simply uses previos performance to predict future performance. This method is designed to be effective despite its simplicity. This model does not account for roster changes, injury updates, or individual player performance as most sports prediction models should. It evaluates the teams as a whole, solely based on win/loss, margin of victory, and home court advantage.

Also, the simulations are random, based on a teams probability of winning. This means the results could vary each time you run it, which requires running it a reasonable amount of times (at least 100 iterations) in order to get meaningful results. Since the predictions tend to vary a little with each run, after running it for multiple iterations, the consistent winner of the 2019-20 season proved to be the Los Angeles Lakers. This can be done by wrapping the script in a loop that runs it for a large number of iterations while keeping track of the winners of each season, and counting each team's wins to find who won most often. This method was used to get the result for the Los Angeles Lakers, but is not shown within this report due to its scope.


# Appendix

```{r echo=FALSE, out.width='100%', fig.width = 8, fig.height = 5, fig.align='center', out.width='.49\\linewidth', fig.cap="\\label{fig:elo_chart}Breakdown of Elo Rating", comment=NA, warning=FALSE}
include_graphics('./EloChart.png')
```

```{r echo=FALSE, out.width='100%', fig.width = 8, fig.height = 5, fig.align='center', out.width='.49\\linewidth', fig.cap="\\label{fig:stat_chart}Statistics Recorded by NBA", comment=NA, warning=FALSE}
recorded_stats <- data.frame(colnames(player_stats[,6:27]))
names(recorded_stats)[1] <- "Statistics"
recorded_stats["Meaning"] <- c("Num. games played", 
                               "Num. minutes played", 
                               "Measure of per-minute production", 
                               "Overall shooting efficiency", 
                               "% of field goal attempts from 3-point range", 
                               "Num. free throw attempts per field goal attempt", 
                               "% of available offensive rebounds that a player grabbed", 
                               "% of available defensive rebounds that a player grabbed", 
                               "% of available total rebounds that a player grabbed", 
                               "% of teammate field goals that a player assisted", 
                               "% of opponent possessions that were stolen by a player", 
                               "% of opponent field goals attempts that were blocked by a player", 
                               "Num. turnovers committed per 100 plays", 
                               "% of team plays used by a player", 
                               "Num. wins contributed by a player from his offense", 
                               "Num. wins contributed by a player from his defense", 
                               "Num. wins contributed by a player", 
                               "Num. wins contributed by a player per 48 minutes", 
                               "Offensive points per 100 possessions above a league-average player", 
                               "Defensive points per 100 possessions above a league-average player", 
                               "Total points per 100 possessions above a league-average player", 
                               "Points per 100 team possessions contributed by a player above a replacement-level player")
kable(recorded_stats, caption="Statistics Recorded by NBA for Every Player")
```



# References

> [1] List of all sporting events canceled around the world during the coronavirus pandemic (https://www.espn.com/olympics/story/_/id/28824781/list-sporting-events-canceled-coronavirus)


> [2] Elo ratings system (https://en.wikipedia.org/wiki/Elo_rating_system)


> [3] FiveThirtyEight NBA Elo Ratings (https://fivethirtyeight.com/features/how-we-calculate-nba-elo-ratings/)


> [4] Compilation of in-depth NBA statistics (https://www.basketball-reference.com/)


> [5] Elo Ratings for NBA Teams (http://practicallypredictable.com/2018/04/15/elo-ratings-for-nba-teams/#more-1019)